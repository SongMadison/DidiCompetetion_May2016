{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = pd.read_csv('TRAIN_nonMissing_withTime_PCA.csv')\n",
    "test = pd.read_csv(\"TEST_nonMissing_withTime_PCA.csv\")\n",
    "\n",
    "feature_names = train.columns # first is just original index\n",
    "features_removed = ['Unnamed: 0'] # original index before ordering\n",
    "feature_names = feature_names[~feature_names.isin(features_removed)]\n",
    "train = train[feature_names]\n",
    "test = test[feature_names]\n",
    "train['DATE'] = pd.to_datetime(train['DATE'])\n",
    "test['DATE'] = pd.to_datetime(test['DATE'])\n",
    "train = train.sort(columns = ['ID','DATE','SLOTID'])\n",
    "test = test.sort(columns = ['ID','DATE','SLOTID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add some more features:\n",
    "#isWeekday, isHoday\n",
    "import datetime\n",
    "import math\n",
    "holidays = pd.read_csv(\"holiday2016.csv\")\n",
    "year = 2016\n",
    "Allholidays=[]\n",
    "for i in range(len(holidays['month'])):\n",
    "    month = holidays.loc[i,'month']\n",
    "    day = holidays.loc[i,'day']\n",
    "    Allholidays.append(datetime.date(year,month,day))\n",
    "    \n",
    "def moreFeatures(train):\n",
    "    dates = train['DATE']\n",
    "    day =[]\n",
    "    isWeekend =[]\n",
    "    isHoliday=[]\n",
    "    for dt in dates:\n",
    "        date = dt.date()\n",
    "        day.append(date.strftime(\"%A\"))\n",
    "        if date.strftime(\"%A\") ==\"Saturday\" or date.strftime(\"%A\") ==\"Sunday\":\n",
    "            isWeekend.append(1)\n",
    "        else:\n",
    "            isWeekend.append(0)\n",
    "            \n",
    "        isHoliday.append(date in Allholidays)\n",
    "    train.loc[:,'weekday'] = pd.Series(day, index=train.index) \n",
    "    train.loc[:,'isWeekend'] = pd.Series(isWeekend, index=train.index) \n",
    "    train.loc[:,'isHoliday'] = pd.Series(isHoliday, index=train.index) \n",
    "    train.loc[:,'DayPeriod_COS1'] = pd.Series([math.cos(sid*1.0/144) for sid in train['SLOTID']],index=train.index)\n",
    "    train.loc[:,'DayPeriod_COS2'] = pd.Series([math.cos(sid*2.0/144) for sid in train['SLOTID']],index=train.index)\n",
    "    train.loc[:,'DayPeriod_SIN1'] = pd.Series([math.sin(sid*1.0/144) for sid in train['SLOTID']],index=train.index)\n",
    "    train.loc[:,'DayPeriod_SIN2'] = pd.Series([math.sin(sid*2.0/144) for sid in train['SLOTID']],index=train.index)\n",
    "\n",
    "moreFeatures(train)\n",
    "moreFeatures(test)\n",
    "#train.to_csv(\"TRAIN_with_AllFeatures.csv\")       \n",
    "#test.to_csv(\"TEST_with_AllFeatures.csv\")    \n",
    "\n",
    "def correctDataType(train):\n",
    "    categorial_features = ['ID','WEATHER_1','WEATHER_2','WEATHER_3','weekday']\n",
    "    #train[categorial_features] = train[categorial_features].apply(pd.Categorical)\n",
    "    train['ID'] =train['ID'].astype(\"category\")\n",
    "    train['WEATHER_1'] =train['WEATHER_1'].astype(\"category\")\n",
    "    train['WEATHER_2'] =train['WEATHER_2'].astype(\"category\")\n",
    "    train['WEATHER_3'] =train['WEATHER_3'].astype(\"category\")\n",
    "    train['weekday'] =train['weekday'].astype(\"category\", )\n",
    "    #train.loc[:,train.columns[~train.columns.isin(categorial_features)]] = \\\n",
    "    #     train[train.columns[~train.columns.isin(categorial_features)]].astype(float)\n",
    "    \n",
    "correctDataType(train)  \n",
    "correctDataType(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import fabs \n",
    "def Accuracy (TRAIN, ypred):\n",
    "    PRED = pd.DataFrame({'ID':TRAIN['ID'].tolist(),'GAP':[val for val in ypred]})\n",
    "    IDs = TRAIN['ID'].drop_duplicates()\n",
    "    s=0\n",
    "    for id in IDs:\n",
    "        t = 0\n",
    "        GAP = TRAIN[TRAIN['ID'].isin([id])]['GAP'].tolist()\n",
    "        GAP_pred = PRED[PRED['ID'].isin([id])]['GAP'].tolist()\n",
    "        count = 0 \n",
    "        for i in range(len(GAP)):\n",
    "            if GAP[i] > 0:\n",
    "                t = t + fabs( (GAP[i]-GAP_pred[i])*1.0/GAP[i])\n",
    "                count = count+1\n",
    "        s = s +   1.0 *t / count   \n",
    "    return s/len(IDs) \n",
    "\n",
    "\n",
    "def Accuracy2 (GAP, ypred):\n",
    "    s = 0;\n",
    "    for i in range(len(ypred)):\n",
    "        if GAP[i] > 0:\n",
    "            s = s + fabs( (GAP[i]-ypred[i])*1.0/GAP[i])  \n",
    "    return s/len(ypred) \n",
    "\n",
    "#Accuracy(train2, ypred_rf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10523510957\n",
      "1.04648580465\n",
      "[ 0.6966433   0.70593566  0.75474322]\n",
      "0.415573536809\n",
      "0.464293947599\n"
     ]
    }
   ],
   "source": [
    "#divide the data into train and validiation, and test set\n",
    "nTRAIN = len(train['ID'])\n",
    "sample_validation = range(nTRAIN-66*144*2, nTRAIN)\n",
    "sample_train = range(nTRAIN-66*144*2)\n",
    "\n",
    "train1 = train.iloc[sample_train,]\n",
    "train2 = train.iloc[sample_validation]\n",
    "slotids_test = test['SLOTID'].drop_duplicates()\n",
    "train2 = train2[train2['SLOTID'].isin(slotids_test)]\n",
    "\n",
    "#pd.Series(range(len(train['GAP'])))[~pd.Series(range(len(train['GAP']))).isin(sample_validation)]\n",
    "GAP_tr = train['GAP']\n",
    "GAP_tr1 = train1['GAP']\n",
    "GAP_tr2 = train2['GAP']\n",
    "GAP_te = test['GAP']\n",
    "\n",
    "feature_names = train.columns[:]\n",
    "feature_removed = ['DATE','GAP','weekday']\n",
    "feature_names = feature_names[~ feature_names.isin(feature_removed)] # remove some IDs\n",
    "features_tr1 = train1[feature_names]\n",
    "features_tr2 = train2[feature_names]\n",
    "features_tr = train[feature_names]\n",
    "features_te = test[feature_names]\n",
    " \n",
    "\n",
    "from math import log1p, expm1\n",
    "from sklearn import tree\n",
    "DTRegressor = tree.DecisionTreeRegressor(max_depth=None,  min_samples_split=5, \n",
    "                             random_state=0)\n",
    "X = features_tr1\n",
    "y = GAP_tr1\n",
    "reg = DTRegressor.fit(X, y)\n",
    "ypred_tree1 = reg.predict(features_tr2)\n",
    "ypred_tree1 = np.round(ypred_tree1)\n",
    "print Accuracy(train2,ypred_tree1)\n",
    "\n",
    "\n",
    "X = features_tr1\n",
    "y = [log1p(val) for val in GAP_tr1.tolist()]\n",
    "reg = DTRegressor.fit(X, y)\n",
    "ypred_tree2 = reg.predict(features_tr2)\n",
    "ypred_tree2 = np.round([expm1(val) for val in ypred_tree2])\n",
    "print Accuracy(train2,ypred_tree2)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "scores = cross_val_score(DTRegressor, features_tr, GAP_tr) # what type of error \n",
    "print scores\n",
    "\n",
    "\n",
    "\n",
    "from math import log1p, expm1\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfRegressor = RandomForestRegressor(n_estimators=150, max_features=10, min_samples_split=5)\n",
    "X = features_tr1\n",
    "y =  GAP_tr1\n",
    "reg = rfRegressor.fit(X, y)\n",
    "ypred_rf1 = reg.predict(features_tr2)\n",
    "ypred_rf1 = np.round(ypred_rf1)\n",
    "\n",
    "print Accuracy(train2,ypred_rf1)\n",
    "\n",
    "#take log first, minimize MSE and then scale back\n",
    "rfRegressor = RandomForestRegressor(n_estimators=150, max_features=10, min_samples_split=5)\n",
    "X = features_tr1\n",
    "y = [log1p(val) for val in GAP_tr1.tolist()]\n",
    "reg = rfRegressor.fit(X, y)\n",
    "ypred_rf = reg.predict(features_tr2)\n",
    "ypred_rf2 = np.round([expm1(val) for val in ypred_rf])\n",
    "print Accuracy(train2,ypred_rf2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1.10523510957\n",
    "1.04648580465\n",
    "[ 0.69445639  0.70651343  0.76441657]\n",
    "0.42266738693   #100 tree\n",
    "0.488925819351"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#divide the data into train and validiation, and test set\n",
    "\n",
    "def forecastError(train, test, k):\n",
    "    nTRAIN = len(train['ID'])\n",
    "    feature_names = train.columns\n",
    "    sample_validation = range(nTRAIN-66*144*k, nTRAIN)\n",
    "    sample_train = range(nTRAIN-66*144*k)\n",
    "\n",
    "    train1 = train.iloc[sample_train,]\n",
    "    train2 = train.iloc[sample_validation]\n",
    "    slotids_test = test['SLOTID'].drop_duplicates()\n",
    "    train2 = train2[train2['SLOTID'].isin(slotids_test)]\n",
    "\n",
    "    #pd.Series(range(len(train['GAP'])))[~pd.Series(range(len(train['GAP']))).isin(sample_validation)]\n",
    "    GAP_tr = train['GAP']\n",
    "    GAP_tr1 = train1['GAP']\n",
    "    GAP_tr2 = train2['GAP']\n",
    "    GAP_te = test['GAP']\n",
    "\n",
    "    feature_names = train.columns[:]\n",
    "    feature_removed = [DATE','GAP','weekday']\n",
    "    feature_names = feature_names[~ feature_names.isin(feature_removed)] # remove some IDs\n",
    "    features_tr1 = train1[feature_names]\n",
    "    features_tr2 = train2[feature_names]\n",
    "    features_tr = train[feature_names]\n",
    "    features_te = test[feature_names]\n",
    "\n",
    "    from math import log1p, expm1\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    rfRegressor = RandomForestRegressor(n_estimators=100, max_features=10, min_samples_split=5)\n",
    "    X=features_tr1\n",
    "    y =  GAP_tr1\n",
    "    rfg = rfRegressor.fit(X, y)\n",
    "    ypred_rf1 = rfg.predict(features_tr2)\n",
    "    ypred_rf1 = np.round(ypred_rf1)\n",
    "\n",
    "    #take log first, minimize MSE and then scale back\n",
    "    y = [log1p(val) for val in GAP_tr1.tolist()]\n",
    "    rfg = rfRegressor.fit(X, y)\n",
    "    ypred_rf2 = rfg.predict(features_tr2)\n",
    "    ypred_rf2 = np.round([expm1(val) for val in ypred_rf2])\n",
    "\n",
    "    return Accuracy(train2,ypred_rf1),Accuracy(train2,ypred_rf2)\n",
    "\n",
    "print forecastError(train,test,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-212-6c45ba6582e5>, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-212-6c45ba6582e5>\"\u001b[0;36m, line \u001b[0;32m35\u001b[0m\n\u001b[0;31m    submitResult2.to_csv('result2.csv'， index = None, columns= None)\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##rf prediction without log tranformation\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "tfRegressor = RandomForestRegressor(n_estimators=200, max_features=10, min_samples_split=5)\n",
    "reg = tfRegressor.fit(features_tr, GAP_tr)\n",
    "ypred_rf = reg.predict(features_te)\n",
    "ypred_rf =np.round(ypred_rf)\n",
    "\n",
    "def submitResult(ypred):\n",
    "    # create the first guess prediction: with the previous gap\n",
    "    import csv\n",
    "    test = pd.read_csv(\"TEST_nonMissing_withTime.csv\")\n",
    "    import datetime\n",
    "    test['DATE'] = pd.to_datetime(test['DATE'])\n",
    "    timeID = []\n",
    "    distID = []\n",
    "    #test1 = test[['ID','DATE','SLOTID','GAP']]\n",
    "    for i in range(len(test['ID'])):\n",
    "        row = test.iloc[i,:]\n",
    "        distID.append(row['ID'])\n",
    "        date = row['DATE'].date()\n",
    "        if date.month <10:\n",
    "            timeID.append(str(date.year)+ '-' +'0'+str(date.month) + '-' +str(date.day) + '-' +str(row['SLOTID']+1)) # \n",
    "        else:\n",
    "            timeID.append(str(date.year)+ '-' +str(date.month) + '-' +str(date.day) + '-' +str(row['SLOTID']+1)) # \n",
    "      \n",
    "        #pred.append(row['GAP_1'])\n",
    "    submitResult =pd.DataFrame({'distID': distID,\n",
    "                            'timeID': timeID,\n",
    "                            'GAP': ypred})   # predicted value\n",
    "    submitResult = submitResult[['distID','timeID','GAP']]\n",
    "    timeSLOTIDs = pd.read_csv('./test_set_1/read_me_1.txt')\n",
    "    submitResult = submitResult[submitResult2['timeID'].isin(timeSLOTIDs ['需预测时间片:'].tolist())]\n",
    "    return submitResult\n",
    "\n",
    "submitResult2 = submitResult(ypred_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   distID          timeID  GAP\n",
      "0       1   2016-01-22-46   10\n",
      "1       1   2016-01-22-58    8\n",
      "2       1   2016-01-22-70    5\n",
      "3       1   2016-01-22-82    5\n",
      "4       1   2016-01-22-94    5\n",
      "5       1  2016-01-22-106   15\n",
      "6       1  2016-01-22-118    7\n",
      "7       1  2016-01-22-130    8\n",
      "8       1  2016-01-22-142    9\n",
      "9       1   2016-01-24-46    5\n"
     ]
    }
   ],
   "source": [
    "print submitResult2[:10]\n",
    "print len(submitResult2['GAP'])\n",
    "submitResult2.to_csv(\"submitResult3.csv\", index = None, header = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
